"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ConversationServiceRecognizer = void 0;
const Exports_js_1 = require("../sdk/Exports.js");
const Exports_js_2 = require("./Exports.js");
class ConversationServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
        this.handleSpeechPhraseMessage = (textBody) => __awaiter(this, void 0, void 0, function* () { return this.handleSpeechPhrase(textBody); });
        this.handleSpeechHypothesisMessage = (textBody) => this.handleSpeechHypothesis(textBody);
    }
    processTypeSpecificMessages(connectionMessage) {
        void connectionMessage;
        return;
    }
    handleRecognizedCallback(result, offset, sessionId) {
        void result;
        void offset;
        void sessionId;
        return;
    }
    handleRecognizingCallback(result, duration, sessionId) {
        void result;
        void duration;
        void sessionId;
        return;
    }
    processSpeechMessages(connectionMessage) {
        return __awaiter(this, void 0, void 0, function* () {
            let processed = false;
            switch (connectionMessage.path.toLowerCase()) {
                case "speech.hypothesis":
                case "speech.fragment":
                    if (!!this.handleSpeechHypothesisMessage) {
                        this.handleSpeechHypothesisMessage(connectionMessage.textBody);
                    }
                    processed = true;
                    break;
                case "speech.phrase":
                    if (!!this.handleSpeechPhraseMessage) {
                        yield this.handleSpeechPhraseMessage(connectionMessage.textBody);
                    }
                    processed = true;
                    break;
                default:
                    break;
            }
            return processed;
        });
    }
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        // Implementing to allow inheritance
        void sessionId;
        void requestId;
        void cancellationReason;
        void errorCode;
        void error;
    }
    handleSpeechPhrase(textBody) {
        return __awaiter(this, void 0, void 0, function* () {
            const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(textBody);
            const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
            let result;
            const resultProps = new Exports_js_1.PropertyCollection();
            resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);
            const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;
            let offset = simpleOffset;
            this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
            if (Exports_js_1.ResultReason.Canceled === resultReason) {
                const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
                const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
                yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
            }
            else {
                if (!(this.privRequestSession.isSpeechEnded && resultReason === Exports_js_1.ResultReason.NoMatch && simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.InitialSilenceTimeout)) {
                    if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {
                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simpleOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, textBody, resultProps);
                    }
                    else {
                        const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(textBody);
                        const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
                        const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, offsetCorrectedJson, resultProps);
                        offset = result.offset;
                    }
                    this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);
                }
            }
        });
    }
    handleSpeechHypothesis(textBody) {
        const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(textBody);
        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
        const resultProps = new Exports_js_1.PropertyCollection();
        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);
        const result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, textBody, resultProps);
        this.privRequestSession.onHypothesis(offset);
        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);
    }
}
exports.ConversationServiceRecognizer = ConversationServiceRecognizer;

//# sourceMappingURL=ConversationServiceRecognizer.js.map
