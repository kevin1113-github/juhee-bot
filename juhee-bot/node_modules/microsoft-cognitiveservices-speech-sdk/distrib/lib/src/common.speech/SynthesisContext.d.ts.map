{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":"AAGA,OAAO,EAAE,qBAAqB,EAAE,MAAM,mCAAmC,CAAC;AAC1E,OAAO,EAAc,iBAAiB,EAAE,MAAM,mBAAmB,CAAC;AAElE;;;GAGG;AACH,qBAAa,gBAAgB;IACzB,OAAO,CAAC,WAAW,CAAkC;IACrD,OAAO,CAAC,qBAAqB,CAAwB;IAErD;;;;OAIG;IACI,UAAU,CAAC,WAAW,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,GAAG,MAAM,GAAG,IAAI;IAIpE;;;OAGG;IACH,IAAW,iBAAiB,CAAC,MAAM,EAAE,qBAAqB,EAEzD;IAEM,MAAM,IAAI,MAAM;IAIhB,mBAAmB,CAAC,iBAAiB,EAAE,iBAAiB,GAAG,IAAI;IAKtE,OAAO,CAAC,qBAAqB;CAqBhC","file":"SynthesisContext.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat.js\";\r\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports.js\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: string | object): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    public setSynthesisSection(speechSynthesizer: SpeechSynthesizer): void {\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext(speechSynthesizer);\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n    }\r\n\r\n    private buildSynthesisContext(speechSynthesizer: SpeechSynthesizer): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    bookmarkEnabled: (!!speechSynthesizer?.bookmarkReached),\r\n                    punctuationBoundaryEnabled: speechSynthesizer?.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!speechSynthesizer?.wordBoundary)),\r\n                    sentenceBoundaryEnabled: speechSynthesizer?.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\r\n                    sessionEndEnabled: true,\r\n                    visemeEnabled: (!!speechSynthesizer?.visemeReceived),\r\n                    wordBoundaryEnabled: speechSynthesizer?.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!speechSynthesizer?.wordBoundary)),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: speechSynthesizer?.autoDetectSourceLanguage\r\n            }\r\n        } as ISynthesisSection;\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string;\r\n        metadataOptions: {\r\n            bookmarkEnabled: boolean;\r\n            wordBoundaryEnabled: string;\r\n            punctuationBoundaryEnabled: string;\r\n            visemeEnabled: boolean;\r\n            sentenceBoundaryEnabled: string;\r\n            sessionEndEnabled: boolean;\r\n        };\r\n    };\r\n    language: {\r\n        autoDetection: boolean;\r\n    };\r\n}\r\n"]}