/**
 * @fileoverview Microsoft Azure Cognitive Services TTS ì—°ë™
 * @description Azure Speech APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜
 * @author kevin1113dev
 */

import sdk from "microsoft-cognitiveservices-speech-sdk";
import { __dirname } from "./const.js";
import { PassThrough } from "stream";
import fs from "node:fs";
import path from "node:path";
import crypto from "node:crypto";
import {
  TextAnalyticsClient,
  AzureKeyCredential,
} from "@azure/ai-text-analytics";

import dotenv from "dotenv";
import { logger } from "./logger.js";

dotenv.config();

/** Azure Speech API í‚¤ */
const SPEECH_KEY: string = process.env.SPEECH_KEY ?? "";

/** Azure Speech API ë¦¬ì „ */
const SPEECH_REGION: string = process.env.SPEECH_REGION ?? "";

/** ê¸°ë³¸ TTS ìŒì„± */
const DEFAULT_VOICE: string = "SeoHyeonNeural";

type TtsCacheStats = {
  hits: number;
  misses: number;
  inflightWaits: number;
  errors: number;
};

declare global {
  // eslint-disable-next-line no-var
  var __juheeTtsCacheStats: TtsCacheStats | undefined;
}

function getTtsCacheStats(): TtsCacheStats {
  if (!globalThis.__juheeTtsCacheStats) {
    globalThis.__juheeTtsCacheStats = {
      hits: 0,
      misses: 0,
      inflightWaits: 0,
      errors: 0,
    };
  }
  return globalThis.__juheeTtsCacheStats;
}

function getShardIdForStats(): string {
  // discord.js ShardingManagerê°€ í™˜ê²½ë³€ìˆ˜ë¡œ SHARD_IDë¥¼ ì£¼ëŠ” ì¼€ì´ìŠ¤ê°€ ë§ìŒ
  const shardId = process.env.SHARD_ID;
  if (shardId && shardId.trim().length > 0) return shardId.trim();

  // ì¼ë¶€ í™˜ê²½ì—ì„  SHARDS="0,1" ê°™ì€ í˜•íƒœë¡œ ì œê³µë  ìˆ˜ ìˆìŒ
  const shards = process.env.SHARDS;
  if (shards && shards.trim().length > 0) {
    const first = shards.split(",")[0]?.trim();
    if (first) return first;
  }

  return "single";
}

function getStatsFilePath(): string {
  if (process.env.TTS_STATS_FILE && process.env.TTS_STATS_FILE.trim().length) {
    return path.resolve(process.env.TTS_STATS_FILE);
  }
  const shardId = getShardIdForStats();
  return path.join(TTS_CACHE_DIR, `tts-stats-${shardId}.json`);
}

let statsLoaded = false;
function loadPersistedStatsOnce() {
  if (statsLoaded) return;
  statsLoaded = true;

  try {
    ensureCacheDir();
    if (!cacheDirReady) return;

    const statsPath = getStatsFilePath();
    if (!fs.existsSync(statsPath)) return;

    const raw = fs.readFileSync(statsPath, "utf8");
    const parsed = JSON.parse(raw);
    const stats = getTtsCacheStats();
    stats.hits = Number(parsed?.hits ?? stats.hits) || 0;
    stats.misses = Number(parsed?.misses ?? stats.misses) || 0;
    stats.inflightWaits = Number(parsed?.inflightWaits ?? stats.inflightWaits) || 0;
    stats.errors = Number(parsed?.errors ?? stats.errors) || 0;
  } catch (e) {
    logger.warn("âš ï¸ TTS ìºì‹œ í†µê³„ ë¡œë“œ ì‹¤íŒ¨:", e);
  }
}

let flushTimer: NodeJS.Timeout | null = null;
let lastFlushAt = 0;

async function flushStatsToDisk() {
  try {
    ensureCacheDir();
    if (!cacheDirReady) return;

    const stats = getTtsCacheStats();
    const statsPath = getStatsFilePath();
    const payload = {
      hits: stats.hits,
      misses: stats.misses,
      inflightWaits: stats.inflightWaits,
      errors: stats.errors,
      updatedAt: new Date().toISOString(),
      pid: process.pid,
    };

    const tmpPath = `${statsPath}.tmp-${process.pid}-${Date.now()}`;
    await fs.promises.writeFile(tmpPath, JSON.stringify(payload));
    await fs.promises.rename(tmpPath, statsPath);
    lastFlushAt = Date.now();
  } catch (e) {
    logger.warn("âš ï¸ TTS ìºì‹œ í†µê³„ ì €ì¥ ì‹¤íŒ¨:", e);
  }
}

function scheduleStatsFlush() {
  // ë„ˆë¬´ ìì£¼ ì“°ì§€ ì•Šë„ë¡ ìµœì†Œ ê°„ê²© + ë””ë°”ìš´ìŠ¤
  const MIN_INTERVAL_MS = 5000;
  const DEBOUNCE_MS = 1000;
  const now = Date.now();
  const waitMs = Math.max(DEBOUNCE_MS, MIN_INTERVAL_MS - (now - lastFlushAt));

  if (flushTimer) return;
  flushTimer = setTimeout(async () => {
    flushTimer = null;
    await flushStatsToDisk();
  }, waitMs);
}

/**
 * TTS ì˜¤ë””ì˜¤ ìºì‹œ ë””ë ‰í† ë¦¬
 *
 * @remarks
 * - ê¸°ë³¸ê°’ì€ í”„ë¡œì íŠ¸ ì‹¤í–‰ ê²½ë¡œ ê¸°ì¤€ `.ttsCache`
 * - í™˜ê²½ë³€ìˆ˜ `TTS_CACHE_DIR`ë¡œ ë³€ê²½ ê°€ëŠ¥
 */
const TTS_CACHE_DIR: string = process.env.TTS_CACHE_DIR
  ? path.resolve(process.env.TTS_CACHE_DIR)
  : path.join(process.cwd(), ".ttsCache");

/** ìºì‹œ íŒŒì¼ ìµœëŒ€ ë³´ê´€ ê¸°ê°„ (ì¼). 0 ì´í•˜ë©´ ë§Œë£Œ ì²´í¬ ì•ˆ í•¨ */
const TTS_CACHE_MAX_AGE_DAYS: number = (() => {
  const raw = process.env.TTS_CACHE_MAX_AGE_DAYS ?? "30";
  const parsed = parseInt(raw, 10);
  return Number.isFinite(parsed) ? parsed : 30;
})();

/** ë™ì¼ ìš”ì²­ ë™ì‹œ í•©ì„± ì¤‘ë³µ ë°©ì§€ */
const inFlightSynthesis: Map<string, Promise<Buffer>> = new Map();

let cacheDirReady = false;

function ensureCacheDir() {
  if (cacheDirReady) return;
  try {
    fs.mkdirSync(TTS_CACHE_DIR, { recursive: true });
    cacheDirReady = true;
  } catch (e) {
    // ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ì‹œì—ë„ TTSëŠ” ê³„ì† ë™ì‘í•´ì•¼ í•¨
    logger.warn("âš ï¸ TTS ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨:", e);
  }
}

function delay(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

function isRetriableErrorMessage(message: string): boolean {
  const m = message.toLowerCase();
  return (
    m.includes("websocket error") ||
    m.includes("internal server error") ||
    m.includes("1011")
  );
}

function bufferToStream(buffer: Buffer): PassThrough {
  const stream = new PassThrough();
  stream.end(buffer);
  return stream;
}

function fileToStream(filePath: string): PassThrough {
  const stream = new PassThrough();
  const rs = fs.createReadStream(filePath);
  rs.on("error", (e) => stream.destroy(e));
  rs.pipe(stream);
  return stream;
}

function sha256Hex(input: string): string {
  return crypto.createHash("sha256").update(input).digest("hex");
}

async function isCacheValid(filePath: string): Promise<boolean> {
  try {
    const stat = await fs.promises.stat(filePath);
    if (TTS_CACHE_MAX_AGE_DAYS <= 0) return true;
    const maxAgeMs = TTS_CACHE_MAX_AGE_DAYS * 24 * 60 * 60 * 1000;
    const ageMs = Date.now() - stat.mtimeMs;
    if (ageMs <= maxAgeMs) return true;
    await fs.promises.unlink(filePath).catch(() => undefined);
    return false;
  } catch {
    return false;
  }
}

async function writeCacheAtomic(filePath: string, data: Buffer) {
  try {
    ensureCacheDir();
    if (!cacheDirReady) return;
    // ì´ë¯¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì“°ì§€ ì•ŠìŒ
    if (fs.existsSync(filePath)) return;

    const tmpPath = `${filePath}.tmp-${process.pid}-${Date.now()}`;
    await fs.promises.writeFile(tmpPath, data);
    await fs.promises.rename(tmpPath, filePath);
  } catch (e) {
    logger.warn("âš ï¸ TTS ìºì‹œ ì €ì¥ ì‹¤íŒ¨:", e);
  }
}

async function synthesizeSsmlToBufferWithRetry(
  speechConfig: sdk.SpeechConfig,
  ssml: string,
  maxRetries: number
): Promise<Buffer> {
  let attempt = 0;

  // eslint-disable-next-line no-constant-condition
  while (true) {
    try {
      const buffer = await new Promise<Buffer>((resolve, reject) => {
        const synthesizer = new sdk.SpeechSynthesizer(speechConfig);
        synthesizer.speakSsmlAsync(
          ssml,
          (result) => {
            try {
              synthesizer.close();
              if (result.errorDetails) {
                const errorMessage = result.errorDetails?.toString() || "";
                const error = new Error(errorMessage);
                (error as any).retriable = isRetriableErrorMessage(errorMessage);
                reject(error);
                return;
              }
              const audioData = result.audioData;
              if (!audioData) {
                reject(new Error("Empty audioData"));
                return;
              }
              resolve(Buffer.from(audioData));
            } catch (e) {
              try {
                synthesizer.close();
              } catch {
                // ignore
              }
              reject(e);
            }
          },
          (error) => {
            try {
              synthesizer.close();
            } catch {
              // ignore
            }
            const errorMessage = error?.toString() || "";
            const err = new Error(errorMessage);
            (err as any).retriable = isRetriableErrorMessage(errorMessage);
            reject(err);
          }
        );
      });

      return buffer;
    } catch (e: any) {
      const retriable = Boolean(e?.retriable);
      const message = e?.message?.toString?.() ?? String(e);

      if (retriable && attempt < maxRetries) {
        attempt += 1;
        logger.debug(`âš ï¸ TTS ì¬ì‹œë„ (${attempt}/${maxRetries})`);
        await delay(1000 * attempt);
        continue;
      }

      logger.error("âŒ TTS í•©ì„± ì˜¤ë¥˜:", message);
      throw e;
    }
  }
}

/** Azure Language API í‚¤ (ì–¸ì–´ ê°ì§€ìš©, í˜„ì¬ ë¯¸ì‚¬ìš©) */
const LANGUAGE_KEY = process.env.LANGUAGE_KEY ?? "";

/** Azure Language API ì—”ë“œí¬ì¸íŠ¸ (í˜„ì¬ ë¯¸ì‚¬ìš©) */
const LANGUAGE_ENDPOINT = process.env.LANGUAGE_ENDPOINT ?? "";

/** ì–¸ì–´ ë¶„ì„ í´ë¼ì´ì–¸íŠ¸ (í˜„ì¬ ë¯¸ì‚¬ìš©) */
const client = new TextAnalyticsClient(
  LANGUAGE_ENDPOINT,
  new AzureKeyCredential(LANGUAGE_KEY)
);

/**
 * Microsoft Azure TTSë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
 * 
 * @param textData - ë³€í™˜í•  í…ìŠ¤íŠ¸
 * @param callback - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì„ ì½œë°± í•¨ìˆ˜
 * @param voiceName - ì‚¬ìš©í•  ìŒì„± ì´ë¦„ (ê¸°ë³¸ê°’: SeoHyeonNeural)
 * @param speed - ì†ë„ ì¡°ì ˆ (0-100, ê¸°ë³¸ê°’: 30)
 * @param retryCount - ì¬ì‹œë„ íšŸìˆ˜ (ë‚´ë¶€ ì‚¬ìš©, ê¸°ë³¸ê°’: 0)
 * 
 * @remarks
 * - ì–¸ì–´ ìë™ ê°ì§€ (í•œêµ­ì–´, ì¼ë³¸ì–´, ì˜ì–´)
 * - ì˜¤ë¥˜ ë°œìƒ ì‹œ ìµœëŒ€ 2ë²ˆ ì¬ì‹œë„
 * - Ogg Opus í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
 * - ì¬ì‹œë„ ê°„ê²©: 1ì´ˆ, 2ì´ˆ (ì ì§„ì  ì¦ê°€)
 */
async function msTTS(
  textData: string,
  callback: Function,
  voiceName: string = DEFAULT_VOICE,
  speed: number = 30,
  retryCount: number = 0
) {
  const MAX_RETRIES = 2;
  const stats = getTtsCacheStats();
  
  try {
    loadPersistedStatsOnce();

    if (!SPEECH_KEY || !SPEECH_REGION) {
      logger.error("Speech API credentials not configured");
      if (typeof callback === 'function') {
        try {
          callback(null);
        } catch (callbackError) {
          logger.error("Error calling callback for missing credentials:", callbackError);
        }
      }
      return;
    }

    ensureCacheDir();

    const speechConfig = sdk.SpeechConfig.fromSubscription(
      SPEECH_KEY,
      SPEECH_REGION
    );

    let language: string;
    let voice: string;
    // const detectedLanguage = await recognizeLanguage(textData);
    const detectedLanguage = (voiceName == 'HyunsuMultilingualNeural') ? 'ko' : quickLanguageDetect(textData);

    switch (detectedLanguage) {
      case "ko":
        language = "ko-KR";
        voice = language + "-" + (voiceName ?? DEFAULT_VOICE);
        break;
      case "ja":
        language = "ja-JP";
        voice = language + "-AoiNeural";
        break;
      case "en":
        language = "en-US";
        voice = language + "-AnaNeural";
        break;
      default:
        language = "ko-KR";
        voice = language + "-" + (voiceName ?? DEFAULT_VOICE);
        break;
    }

    speechConfig.speechSynthesisOutputFormat =
      sdk.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus;
    speechConfig.speechSynthesisLanguage = language;
    speechConfig.speechSynthesisVoiceName = voice;

    const speechSynthesizer = new sdk.SpeechSynthesizer(speechConfig);
    const ssml = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="${language}">
    <voice name="${voice}">
      <prosody rate="+${speed ?? 30}%">${textData}</prosody>
    </voice>
  </speak>`;
    const cacheKey = sha256Hex(
      JSON.stringify({
        v: 1,
        format: "Ogg24Khz16BitMonoOpus",
        language,
        voice,
        speed,
        textData
      })
    );
    const cacheFilePath = path.join(TTS_CACHE_DIR, `${cacheKey}.ogg`);

    // ìºì‹œ íˆíŠ¸
    if (cacheDirReady && (await isCacheValid(cacheFilePath))) {
      logger.debug(`ğŸ’¾ TTS ìºì‹œ íˆíŠ¸: ${cacheKey}`);
      stats.hits += 1;
      scheduleStatsFlush();
      if (typeof callback === "function") {
        try {
          callback(fileToStream(cacheFilePath));
        } catch (callbackError) {
          logger.error("âŒ TTS ìºì‹œ ìŠ¤íŠ¸ë¦¼ ì½œë°± ì‹¤íŒ¨:", callbackError);
        }
      }
      return;
    }

    // ë™ì¼ í‚¤ ë™ì‹œ ìš”ì²­ì€ í•œ ë²ˆë§Œ í•©ì„±
    let synthesisPromise = inFlightSynthesis.get(cacheKey);
    if (!synthesisPromise) {
      stats.misses += 1;
      scheduleStatsFlush();
      synthesisPromise = (async () => {
        const buffer = await synthesizeSsmlToBufferWithRetry(
          speechConfig,
          ssml,
          MAX_RETRIES
        );
        await writeCacheAtomic(cacheFilePath, buffer);
        return buffer;
      })();
      inFlightSynthesis.set(cacheKey, synthesisPromise);
    } else {
      stats.inflightWaits += 1;
      scheduleStatsFlush();
    }

    try {
      const buffer = await synthesisPromise;
      if (typeof callback === "function") {
        try {
          callback(bufferToStream(buffer));
        } catch (callbackError) {
          logger.error("âŒ TTS ìŠ¤íŠ¸ë¦¼ ì½œë°± ì‹¤íŒ¨:", callbackError);
        }
      }
    } catch (e) {
      stats.errors += 1;
      scheduleStatsFlush();
      throw e;
    } finally {
      // ì™„ë£Œ/ì‹¤íŒ¨ ìƒê´€ì—†ì´ in-flight ì œê±°
      if (inFlightSynthesis.get(cacheKey) === synthesisPromise) {
        inFlightSynthesis.delete(cacheKey);
      }
    }

    return;
  } catch (error) {
    logger.error("âŒ TTS ì´ˆê¸°í™” ì‹¤íŒ¨:", error);
    stats.errors += 1;
    scheduleStatsFlush();

    // í•©ì„± ì¬ì‹œë„ëŠ” synthesizeSsmlToBufferWithRetryì—ì„œ ì²˜ë¦¬.
    if (typeof callback === "function") {
      try {
        callback(null);
      } catch (callbackError) {
        logger.error("âŒ ìµœì¢… ì‹¤íŒ¨ ì½œë°± ì˜¤ë¥˜:", callbackError);
      }
    }
  }
}

/**
 * Azure Language APIë¥¼ ì‚¬ìš©í•œ ì–¸ì–´ ì¸ì‹ í•¨ìˆ˜ (í˜„ì¬ ë¹„í™œì„±í™”)
 * API í˜¸ì¶œ ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ë¡œì»¬ ì–¸ì–´ ê°ì§€ ì‚¬ìš©
 */
// async function recognizeLanguage(text: string): Promise<string> {
//   try {
//     if (recognizeOption && LANGUAGE_KEY && LANGUAGE_ENDPOINT) {
//       const result: DetectLanguageResult = (await client.detectLanguage([text]))[0];
//       if (!result.error) {
//         logger.debug(`ğŸŒ Detected language: ${result.primaryLanguage.iso6391Name}`);
//         return result.primaryLanguage.iso6391Name;
//       } else {
//         logger.warn("Language detection failed, defaulting to Korean:", result.error);
//         return 'ko';
//       }
//     } else {
//       return 'ko';
//     }
//   } catch (error) {
//     logger.error("Error in language recognition:", error);
//     return 'ko';
//   }
// }

/**
 * ë¹ ë¥¸ ë¡œì»¬ ì–¸ì–´ ê°ì§€
 * API í˜¸ì¶œ ì—†ì´ ì •ê·œì‹ìœ¼ë¡œ ì–¸ì–´ íŒë³„
 * 
 * @param text - ê°ì§€í•  í…ìŠ¤íŠ¸
 * @returns ì–¸ì–´ ì½”ë“œ ('ko', 'ja', 'en')
 * 
 * @remarks
 * - í•œê¸€ ë¬¸ì í¬í•¨ ì‹œ: 'ko'
 * - ì¼ë³¸ì–´ ë¬¸ì í¬í•¨ ì‹œ: 'ja'
 * - ì˜ì–´ ë¬¸ìë§Œ í¬í•¨ ì‹œ: 'en'
 * - ê·¸ ì™¸: 'ko' (ê¸°ë³¸ê°’)
 */
function quickLanguageDetect(text: string): string {
  const koreanRegex = /[ã„±-ã…|ã…-ã…£|ê°€-í£]/;
  const japaneseRegex = /[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠ]/;
  const englishRegex = /^[a-zA-Z\s\d\.,!?]+$/;

  if (koreanRegex.test(text)) return "ko";
  if (japaneseRegex.test(text)) return "ja";
  if (englishRegex.test(text)) return "en";
  return "ko"; // ê¸°ë³¸ê°’
}

export default msTTS;
